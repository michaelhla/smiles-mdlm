train: chebi
valid: chebi
tokenizer_name_or_path: bert-base-uncased  # Keep BERT tokenizer for text
smiles_tokenizer_type: custom  # Indicates we're using custom SMILESTokenizer
cache_dir: ./cache
wrap: True
streaming: False
model:
  smiles_length: 256  # Adjust based on your SMILES lengths
  text_length: 512    # Adjust based on your text lengths